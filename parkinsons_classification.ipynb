{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifications with ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
      "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
      "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
      "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
      "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
      "\n",
      "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
      "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
      "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
      "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
      "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
      "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
      "\n",
      "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
      "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
      "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
      "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
      "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
      "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.266482  2.301442  0.284654  \n",
      "1  0.335590  2.486855  0.368674  \n",
      "2  0.311173  2.342259  0.332634  \n",
      "3  0.334147  2.405554  0.368975  \n",
      "4  0.234513  2.332180  0.410335  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a pandas dataframe\n",
    "\n",
    "# File paths\n",
    "path = 'Data\\parkinsons.data'\n",
    "\n",
    "# Using pd.read_csv() method to read the data into a pandas dataframe\n",
    "classification_df = pd.read_csv(path)\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "print(classification_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove name column\n",
    "classification_df = classification_df.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 22)\n",
      "(195, 1)\n"
     ]
    }
   ],
   "source": [
    "# Build model to create classifications based on classifications_df.status (1 = Parkinsons, 0 = Healthy)\n",
    "\n",
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the features (X) and target (y) sets\n",
    "X = classification_df.drop(columns='status')\n",
    "y = classification_df[['status']]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8493150684931506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Data Score: {classifier.score(X_train_scaled, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Prediction  Actual\n",
      "0           1       1\n",
      "1           1       1\n",
      "2           1       1\n",
      "3           1       0\n",
      "4           1       1\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\n",
    "    'Prediction': predictions,\n",
    "    'Actual': y_test['status']\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Print the first 5 rows of the results\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Store prediction and accuracy scores for logistic regression\n",
    "logistic_regression_prediction = accuracy_score(y_test['status'], predictions)\n",
    "logistic_regression_accuracy = accuracy_score(y_test['status'], predictions)\n",
    "\n",
    "print(accuracy_score(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  4]\n",
      " [ 3 34]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70        12\n",
      "           1       0.89      0.92      0.91        37\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.81      0.79      0.80        49\n",
      "weighted avg       0.85      0.86      0.85        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fit the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(f'Training Data Score: {rf_model.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Data Score: {rf_model.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\n",
    "    'Prediction': predictions,\n",
    "    'Actual': y_test['status']\n",
    "}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Prediction  Actual\n",
      "0           1       1\n",
      "1           1       1\n",
      "2           1       1\n",
      "3           0       0\n",
      "4           1       1\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 rows of the results\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "# Store the rf_model predictions and accuracy score\n",
    "rf_predictions = predictions\n",
    "rf_acc_score = accuracy_score(y_test['status'], predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(accuracy_score(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  4]\n",
      " [ 1 36]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.90      0.97      0.94        37\n",
      "\n",
      "    accuracy                           0.90        49\n",
      "   macro avg       0.89      0.82      0.85        49\n",
      "weighted avg       0.90      0.90      0.89        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8767123287671232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Data Score: {svm_model.score(X_train_scaled, y_train)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Prediction  Actual\n",
      "0           1       1\n",
      "1           1       1\n",
      "2           1       1\n",
      "3           1       0\n",
      "4           1       1\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = svm_model.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\n",
    "    'Prediction': predictions,\n",
    "    'Actual': y_test['status']\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Print the first 5 rows of the results\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "# Store the SVM model predictions and accuracy score\n",
    "svm_predictions = predictions\n",
    "svm_acc_score = accuracy_score(y_test['status'], predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(accuracy_score(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  4]\n",
      " [ 2 35]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.90      0.95      0.92        37\n",
      "\n",
      "    accuracy                           0.88        49\n",
      "   macro avg       0.85      0.81      0.82        49\n",
      "weighted avg       0.87      0.88      0.87        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras tuner to use to create a model with hyperparameters\n",
    "\n",
    "# Import dependencies\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use keras tuner to find the best learning rate and parameters for the model\n",
    "\n",
    "# Define the model\n",
    "def create_nn_model(hp):\n",
    "    # Create a sequential model\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # Add our first hidden layer where the input dimensions are the 45 columns of our dataset\n",
    "    # Make Keras Tuner find the optimal number of nodes in this layer\n",
    "    # Make Keras Tuner find the optimal activation function to use in this layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "                                        min_value=1,\n",
    "                                        max_value=80,\n",
    "                                        step=2), input_dim=43, activation=hp.Choice('first_activation', ['relu', 'tanh', 'sigmoid'])))\n",
    "    \n",
    "    # Make Keras Tuner find the optimal number of hidden layers to use\n",
    "    # Make Keras Tuner find the optimal number of nodes to use in each hidden layer\n",
    "    # Make Keras Tuner find the optimal activation function to use in each hidden layer\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        nn.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=1,\n",
    "                                            max_value=80,\n",
    "                                            step=2),\n",
    "                               activation=hp.Choice('activation_' + str(i), ['relu', 'tanh', 'sigmoid'])))\n",
    "        \n",
    "    # Add our output layer\n",
    "    # Make Keras Tuner find the optimal activation function to use in the output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=hp.Choice('output_activation', ['relu', 'tanh', 'sigmoid'])))\n",
    "\n",
    "    # Compile our model\n",
    "    # Make Keras Tuner find the optimal learning rate to use\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), metrics=[\"accuracy\"])\n",
    "\n",
    "    # Return our model\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras Tuner Hyperband tuner\n",
    "tuner = kt.Hyperband(create_nn_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=40,\n",
    "                     factor=3,\n",
    "                     directory='KerasTunerTrials',\n",
    "                     project_name='KerasTunerTrials')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amd_dev_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
