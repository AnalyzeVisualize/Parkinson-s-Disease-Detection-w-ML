{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifications with ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
      "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
      "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
      "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
      "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
      "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
      "\n",
      "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
      "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
      "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
      "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
      "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
      "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
      "\n",
      "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
      "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
      "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
      "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
      "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
      "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
      "\n",
      "    spread2        D2       PPE  \n",
      "0  0.266482  2.301442  0.284654  \n",
      "1  0.335590  2.486855  0.368674  \n",
      "2  0.311173  2.342259  0.332634  \n",
      "3  0.334147  2.405554  0.368975  \n",
      "4  0.234513  2.332180  0.410335  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a pandas dataframe\n",
    "\n",
    "# File paths\n",
    "path = 'Data\\parkinsons.data'\n",
    "\n",
    "# Using pd.read_csv() method to read the data into a pandas dataframe\n",
    "classification_df = pd.read_csv(path)\n",
    "\n",
    "# Print the first 5 rows of the dataframe\n",
    "print(classification_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove name column\n",
    "classification_df = classification_df.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(195, 22)\n",
      "(195, 1)\n"
     ]
    }
   ],
   "source": [
    "# Build model to create classifications based on classifications_df.status (1 = Parkinsons, 0 = Healthy)\n",
    "\n",
    "# Import dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create the features (X) and target (y) sets\n",
    "X = classification_df.drop(columns='status')\n",
    "y = classification_df[['status']]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8493150684931506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a LogisticRegression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Data Score: {classifier.score(X_train_scaled, y_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Prediction  Actual\n",
      "0           1       1\n",
      "1           1       1\n",
      "2           1       1\n",
      "3           1       0\n",
      "4           1       1\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\n",
    "    'Prediction': predictions,\n",
    "    'Actual': y_test['status']\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Print the first 5 rows of the results\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Store prediction and accuracy scores for logistic regression\n",
    "logistic_regression_prediction = accuracy_score(y_test['status'], predictions)\n",
    "logistic_regression_accuracy = accuracy_score(y_test['status'], predictions)\n",
    "\n",
    "print(accuracy_score(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  4]\n",
      " [ 3 34]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.67      0.70        12\n",
      "           1       0.89      0.92      0.91        37\n",
      "\n",
      "    accuracy                           0.86        49\n",
      "   macro avg       0.81      0.79      0.80        49\n",
      "weighted avg       0.85      0.86      0.85        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78)\n",
    "\n",
    "# Fit the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(f'Training Data Score: {rf_model.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Data Score: {rf_model.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = rf_model.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\n",
    "    'Prediction': predictions,\n",
    "    'Actual': y_test['status']\n",
    "}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Prediction  Actual\n",
      "0           1       1\n",
      "1           1       1\n",
      "2           1       1\n",
      "3           0       0\n",
      "4           1       1\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 rows of the results\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8979591836734694\n"
     ]
    }
   ],
   "source": [
    "# Store the rf_model predictions and accuracy score\n",
    "rf_predictions = predictions\n",
    "rf_acc_score = accuracy_score(y_test['status'], predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(accuracy_score(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  4]\n",
      " [ 1 36]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.67      0.76        12\n",
      "           1       0.90      0.97      0.94        37\n",
      "\n",
      "    accuracy                           0.90        49\n",
      "   macro avg       0.89      0.82      0.85        49\n",
      "weighted avg       0.90      0.90      0.89        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.8767123287671232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\sklearn\\utils\\validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Create a support vector machine classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create the SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Training Data Score: {svm_model.score(X_train_scaled, y_train)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Prediction  Actual\n",
      "0           1       1\n",
      "1           1       1\n",
      "2           1       1\n",
      "3           1       0\n",
      "4           1       1\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = svm_model.predict(X_test_scaled)\n",
    "results = pd.DataFrame({\n",
    "    'Prediction': predictions,\n",
    "    'Actual': y_test['status']\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# Print the first 5 rows of the results\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8775510204081632\n"
     ]
    }
   ],
   "source": [
    "# Store the SVM model predictions and accuracy score\n",
    "svm_predictions = predictions\n",
    "svm_acc_score = accuracy_score(y_test['status'], predictions)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(accuracy_score(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  4]\n",
      " [ 2 35]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.67      0.73        12\n",
      "           1       0.90      0.95      0.92        37\n",
      "\n",
      "    accuracy                           0.88        49\n",
      "   macro avg       0.85      0.81      0.82        49\n",
      "weighted avg       0.87      0.88      0.87        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "print(classification_report(y_test['status'], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From b:\\CONDA\\install\\envs\\amd_dev_2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a neural network model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import keras tuner to use to create a model with hyperparameters\n",
    "\n",
    "# Import dependencies\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use keras tuner to find the best learning rate and parameters for the model\n",
    "\n",
    "# Define the model\n",
    "def create_nn_model(hp):\n",
    "    # Create a sequential model\n",
    "    nn = tf.keras.models.Sequential()\n",
    "\n",
    "    # Add our first hidden layer where the input dimensions are the 45 columns of our dataset\n",
    "    # Make Keras Tuner find the optimal number of nodes in this layer\n",
    "    # Make Keras Tuner find the optimal activation function to use in this layer\n",
    "    nn.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "                                        min_value=1,\n",
    "                                        max_value=80,\n",
    "                                        step=2), input_dim=22, activation=hp.Choice('first_activation', ['relu', 'tanh', 'sigmoid'])))\n",
    "    \n",
    "    # Make Keras Tuner find the optimal number of hidden layers to use\n",
    "    # Make Keras Tuner find the optimal number of nodes to use in each hidden layer\n",
    "    # Make Keras Tuner find the optimal activation function to use in each hidden layer\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        nn.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=1,\n",
    "                                            max_value=80,\n",
    "                                            step=2),\n",
    "                               activation=hp.Choice('activation_' + str(i), ['relu', 'tanh', 'sigmoid'])))\n",
    "        \n",
    "    # Add our output layer\n",
    "    # Make Keras Tuner find the optimal activation function to use in the output layer\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation=hp.Choice('output_activation', ['relu', 'tanh', 'sigmoid'])))\n",
    "\n",
    "    # Compile our model\n",
    "    # Make Keras Tuner find the optimal learning rate to use[1e-2, 1e-3, 1e-4]\n",
    "    nn.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(hp.Choice('learning_rate', )), metrics=[\"accuracy\"])\n",
    "\n",
    "    # Return our model\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from KerasTunerTrials\\KerasTunerTrials\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Create a Keras Tuner Hyperband tuner\n",
    "tuner = kt.Hyperband(create_nn_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=40,\n",
    "                     factor=3,\n",
    "                     directory='KerasTunerTrials',\n",
    "                     project_name='KerasTunerTrials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 84 Complete [00h 00m 04s]\n",
      "val_accuracy: 0.7551020383834839\n",
      "\n",
      "Best val_accuracy So Far: 0.9387755393981934\n",
      "Total elapsed time: 00h 03m 13s\n"
     ]
    }
   ],
   "source": [
    "# Run the Keras Tuner search for best hyperparameters\n",
    "tuner.search(X_train_scaled, y_train, epochs=40, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first_units': 57,\n",
       " 'first_activation': 'relu',\n",
       " 'num_layers': 4,\n",
       " 'units_0': 53,\n",
       " 'activation_0': 'tanh',\n",
       " 'output_activation': 'sigmoid',\n",
       " 'learning_rate': 0.01,\n",
       " 'units_1': 65,\n",
       " 'activation_1': 'relu',\n",
       " 'units_2': 59,\n",
       " 'activation_2': 'sigmoid',\n",
       " 'units_3': 59,\n",
       " 'activation_3': 'relu',\n",
       " 'units_4': 19,\n",
       " 'activation_4': 'sigmoid',\n",
       " 'tuner/epochs': 40,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 0,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "# Display the optimal hyperparameters\n",
    "best_hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.21\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.22\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.23\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.24\n",
      "2/2 - 0s - loss: 0.3370 - accuracy: 0.9388 - 176ms/epoch - 88ms/step\n",
      "Loss: 0.33695879578590393, Accuracy: 0.9387755393981934\n"
     ]
    }
   ],
   "source": [
    "# Create a new model with the optimal hyperparameters\n",
    "optimized_model = tuner.get_best_models(1)[0]\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "optimized_model_loss, optimized_model_accuracy = optimized_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "\n",
    "# Print the model loss and accuracy results\n",
    "print(f\"Loss: {optimized_model_loss}, Accuracy: {optimized_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy to use np.round() method to round the predictions to 0 or 1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[0.9982607 ]\n",
      " [0.03115629]\n",
      " [0.99989784]\n",
      " [0.02316914]\n",
      " [0.9998979 ]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = optimized_model.predict(X_test_scaled)\n",
    "\n",
    "# Print the first 5 predictions\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     status\n",
      "132       1\n",
      "16        1\n",
      "18        1\n",
      "51        0\n",
      "164       1\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 actual values\n",
    "print(y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9387755102040817\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score\n",
    "print(accuracy_score(y_test, np.round(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  1]\n",
      " [ 2 35]]\n"
     ]
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "print(confusion_matrix(y_test, np.round(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        12\n",
      "           1       0.97      0.95      0.96        37\n",
      "\n",
      "    accuracy                           0.94        49\n",
      "   macro avg       0.91      0.93      0.92        49\n",
      "weighted avg       0.94      0.94      0.94        49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store the optimized model predictions and accuracy score\n",
    "nn_predictions = predictions\n",
    "nn_acc_score = accuracy_score(y_test, np.round(predictions))\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, np.round(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to compare the models\n",
    "models = ['Logistic Regression', 'Random Forest Classifier', 'Support Vector Machine', 'Neural Network']\n",
    "model_predictions = [logistic_regression_prediction, rf_predictions, svm_predictions, nn_predictions]\n",
    "model_acc_scores = [logistic_regression_accuracy, rf_acc_score, svm_acc_score, nn_acc_score]\n",
    "model_comparison_df = pd.DataFrame({\n",
    "    'Model': models,\n",
    "    'Predictions': model_predictions,\n",
    "    'Accuracy Score': model_acc_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the values in the Predictions column for Model: Neural Network to 0 or 1\n",
    "model_comparison_df.loc[3, 'Predictions'] = np.round(model_comparison_df.loc[3, 'Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Predictions</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, ...</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, ...</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network</td>\n",
       "      <td>[1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>0.938776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  \\\n",
       "0       Logistic Regression   \n",
       "1  Random Forest Classifier   \n",
       "2    Support Vector Machine   \n",
       "3            Neural Network   \n",
       "\n",
       "                                         Predictions  Accuracy Score  \n",
       "0                                           0.857143        0.857143  \n",
       "1  [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, ...        0.897959  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, ...        0.877551  \n",
       "3  [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, ...        0.938776  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the model comparison dataframe\n",
    "model_comparison_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amd_dev_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
